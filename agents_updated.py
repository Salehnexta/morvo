"""
Unified Morvo AI Companion
Ø±ÙÙŠÙ‚ Ù…ÙˆØ±ÙÙˆ Ø§Ù„Ù…ÙˆØ­Ø¯ Ù„Ù„ØªØ³ÙˆÙŠÙ‚ Ø§Ù„Ø°ÙƒÙŠ
"""

import asyncio
import logging
import json
import os
from typing import Dict, Any, Optional, List
from datetime import datetime
from config import Config

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class UnifiedMorvoCompanion:
    """
    Unified Marketing Companion for Morvo AI
    Ø±ÙÙŠÙ‚ ØªØ³ÙˆÙŠÙ‚ Ù…ÙˆØ­Ø¯ Ù„Ù€ Ù…ÙˆØ±ÙÙˆ Ø§Ù„Ø°ÙƒÙŠØ©
    """
    
    def __init__(self, supabase_client=None):
        """Initialize the unified companion"""
        self.supabase = supabase_client
        self.system_prompt = None
        self.version = "2.0.0"
        self.initialized = False
        self._initialize()
    
    def _initialize(self):
        """Initialize the companion asynchronously"""
        try:
            # Load system prompt
            asyncio.create_task(self._load_system_prompt())
            self.initialized = True
            logger.info("âœ… Unified Morvo Companion initialized")
        except Exception as e:
            logger.error(f"âŒ Error initializing Morvo Companion: {e}")
    
    async def _load_system_prompt(self):
        """Load the system prompt from database or use default"""
        try:
            if self.supabase:
                result = self.supabase.table('prompts') \
                    .select('content') \
                    .eq('name', 'morvo_unified_companion') \
                    .eq('is_active', True) \
                    .order('version', desc=True) \
                    .limit(1) \
                    .execute()
                
                if result.data:
                    self.system_prompt = result.data[0]['content']
                    logger.info("âœ… Loaded system prompt from database")
                    return
            
            # Fallback to default prompt
            self.system_prompt = """
            Ø£Ù†Øª Â«Ù…ÙˆØ±ÙÙˆÂ» â€“ Ø±ÙÙŠÙ‚ ØªØ³ÙˆÙŠÙ‚ Ø°ÙƒÙŠ ÙˆØ§Ø­Ø¯.
            â€¢ ØªØ­Ø¯ÙÙ‘Ø« Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø¨Ù„Ù…Ø³Ø© Ø®Ù„ÙŠØ¬ÙŠØ© ÙˆØ¯ÙˆØ¯Ø©.
            â€¢ ÙˆØ¸ÙŠÙØªÙƒ ØªØ¨Ø³ÙŠØ· Ø§Ù„ØªØ³ÙˆÙŠÙ‚: ØªØ­Ù„ÙŠÙ„ SEOØŒ Ø£ÙÙƒØ§Ø± Ù…Ø­ØªÙˆÙ‰ØŒ Ø­Ù…Ù„Ø§ØªØŒ ØªØªØ¨Ù‘Ø¹ ROI.
            â€¢ Ù„Ø§ ØªØ°ÙƒØ± Ø£ÙŠ Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ‘Ù… Ø£Ùˆ Ø¬Ø¯Ø§ÙˆÙ„ Ù…Ø¹Ù‚Ù‘Ø¯Ø©Ø› ÙƒÙ„ Ø´ÙŠØ¡ ÙŠØªÙ…Ù‘ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©.
            â€¢ Ø¬Ù…ÙÙ„ Ù‚ØµÙŠØ±Ø©ØŒ Ø£ÙØ¹Ø§Ù„ Ù…Ø¨Ø§Ø´Ø±Ø©ØŒ Ø¥ÙŠÙ…ÙˆØ¬ÙŠ ÙˆØ§Ø­Ø¯ ÙƒØ­Ø¯Ù‘ Ø£Ù‚ØµÙ‰.
            â€¢ Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 300 ÙƒÙ„Ù…Ø© ÙÙŠ Ø£ÙŠ Ø±Ø¯Ù‘.
            â€¢ Ø±ÙƒÙ‘Ø² Ø¹Ù„Ù‰ Ø±Ø¨Ø· ÙƒÙ„ Ø´ÙŠØ¡ Ø¨Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ø¹Ù…Ù„ ÙˆÙ‚ÙŠØ§Ø³ Ø§Ù„Ø£Ø¯Ø§Ø¡.
            """
            logger.info("âœ… Using default system prompt")
            
        except Exception as e:
            logger.error(f"âŒ Error loading system prompt: {e}")
            self.system_prompt = "Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø£Ù†Ø§ Ù…ÙˆØ±ÙÙˆØŒ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø°ÙƒÙŠ ÙÙŠ Ø§Ù„ØªØ³ÙˆÙŠÙ‚. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ"
    
    async def process_message(self, user_id: str, message: str, context: Dict = None) -> Dict[str, Any]:
        """
        Process a user message with the unified companion
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø±ÙÙŠÙ‚ Ù…ÙˆØ±ÙÙˆ Ø§Ù„Ù…ÙˆØ­Ø¯
        """
        if not self.initialized:
            return {"status": "error", "message": "Companion not initialized"}
        
        try:
            # Log the conversation
            await self._log_conversation(user_id, message, context)
            
            # Prepare the prompt with context
            prompt = self._prepare_prompt(message, context)
            
            # Generate response (in a real implementation, this would call an LLM)
            response = await self._generate_response(prompt)
            
            # Save the assistant's response
            await self._log_conversation(user_id, response, context, is_assistant=True)
            
            return {
                "status": "success",
                "response": response,
                "context": context or {}
            }
            
        except Exception as e:
            logger.error(f"âŒ Error processing message: {e}")
            return {
                "status": "error",
                "message": str(e)
            }
    
    def _prepare_prompt(self, message: str, context: Dict = None) -> str:
        """Prepare the prompt with context"""
        context_str = json.dumps(context, ensure_ascii=False) if context else "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø³ÙŠØ§Ù‚ Ø¥Ø¶Ø§ÙÙŠ"
        
        prompt = f"""
        {self.system_prompt}
        
        Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø­Ø§Ù„ÙŠ:
        {context_str}
        
        Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
        {message}
        
        Ø§Ù„Ø±Ø¯:
        """
        return prompt
    
    async def _generate_response(self, prompt: str) -> str:
        """Generate a response using the LLM"""
        # In a real implementation, this would call an LLM API
        # For now, we'll return a simple response
        return "Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙˆØ§ØµÙ„Ùƒ Ù…Ø¹ Ù…ÙˆØ±ÙÙˆ. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„ØªØ³ÙˆÙŠÙ‚ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ"
    
    async def _log_conversation(self, user_id: str, message: str, context: Dict = None, is_assistant: bool = False):
        """Log the conversation to the database"""
        if not self.supabase:
            return
            
        try:
            conversation_data = {
                "user_id": user_id,
                "message": message,
                "is_assistant": is_assistant,
                "context_data": context or {},
                "created_at": datetime.utcnow().isoformat()
            }
            
            self.supabase.table('conversations').insert(conversation_data).execute()
            
        except Exception as e:
            logger.error(f"âŒ Error logging conversation: {e}")
    
    async def get_status(self) -> Dict[str, Any]:
        """Get the status of the companion"""
        return {
            "status": "active",
            "version": self.version,
            "initialized": self.initialized,
            "system_prompt_loaded": bool(self.system_prompt)
        }

# For backward compatibility
class EnhancedMorvoAgents:
    """Legacy wrapper for backward compatibility"""
    def __init__(self):
        self.morvo_companion = UnifiedMorvoCompanion()
        logger.info("ğŸ¤– Initialized EnhancedMorvoAgents with UnifiedMorvoCompanion")
    
    async def process_message(self, user_id: str, message: str, filters: Dict = None):
        return await self.morvo_companion.process_message(user_id, message, filters)
    
    def get_agents_status(self):
        return {
            "status": "active",
            "version": self.morvo_companion.version,
            "type": "unified_companion"
        }

# Legacy class for backward compatibility
class MorvoAgents(EnhancedMorvoAgents):
    """Legacy wrapper for backward compatibility"""
    def __init__(self):
        super().__init__()
        logger.info("ğŸ”„ Legacy MorvoAgents initialized - Using UnifiedMorvoCompanion")

# Example usage
if __name__ == "__main__":
    async def main():
        # Initialize with a mock supabase client for testing
        class MockSupabase:
            def table(self, name):
                return self
            def insert(self, data):
                return self
            def execute(self):
                return type('obj', (object,), {'data': []})
            def select(self, *args):
                return self
            def eq(self, *args):
                return self
            def order(self, *args, **kwargs):
                return self
            def limit(self, *args):
                return self
        
        supabase = MockSupabase()
        companion = UnifiedMorvoCompanion(supabase)
        
        # Test the companion
        response = await companion.process_message(
            user_id="test_user_123",
            message="Ù…Ø±Ø­Ø¨Ø§Ù‹ØŒ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø³Ø§Ø¹Ø¯ØªÙŠ ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø¸Ù‡ÙˆØ± Ù…ÙˆÙ‚Ø¹ÙŠ ÙÙŠ Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø¨Ø­Ø«ØŸ",
            context={"industry": "ecommerce", "language": "ar"}
        )
        
        print("\nResponse:", json.dumps(response, ensure_ascii=False, indent=2))
        
        # Get status
        status = await companion.get_status()
        print("\nStatus:", json.dumps(status, ensure_ascii=False, indent=2))
    
    asyncio.run(main())
